{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè† House Price Prediction - Complete ML Pipeline\n",
    "\n",
    "**A Professional Machine Learning Project**\n",
    "\n",
    "This notebook implements a complete end-to-end ML pipeline for predicting house prices in Bangalore, including:\n",
    "- Data loading and preprocessing\n",
    "- Exploratory Data Analysis (EDA) with visualizations\n",
    "- Training and comparison of 8 different ML models\n",
    "- Model evaluation and selection\n",
    "- Interactive prediction system\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import joblib\n",
    "\n",
    "# Display settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 2. Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_range(value):\n",
    "    \"\"\"Convert range strings like '3307 - 3464' to their average.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    \n",
    "    value_str = str(value).strip()\n",
    "    \n",
    "    # Handle ranges (e.g., \"3307 - 3464\")\n",
    "    if '-' in value_str:\n",
    "        parts = value_str.split('-')\n",
    "        if len(parts) == 2:\n",
    "            try:\n",
    "                num1 = float(parts[0].strip())\n",
    "                num2 = float(parts[1].strip())\n",
    "                return (num1 + num2) / 2\n",
    "            except ValueError:\n",
    "                return np.nan\n",
    "    \n",
    "    # Try to convert to float\n",
    "    try:\n",
    "        return float(value_str)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def extract_bhk_number(size_str):\n",
    "    \"\"\"Extract number from BHK/Bedroom strings (e.g., '3 BHK' -> 3).\"\"\"\n",
    "    if pd.isna(size_str):\n",
    "        return np.nan\n",
    "    \n",
    "    size_str = str(size_str).strip().upper()\n",
    "    \n",
    "    # Extract number from strings like \"3 BHK\", \"4 Bedroom\", \"1 RK\"\n",
    "    for word in size_str.split():\n",
    "        try:\n",
    "            num = int(word)\n",
    "            return num\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def _normalize_col_name(name: str) -> str:\n",
    "    \"\"\"Normalize column names for matching.\"\"\"\n",
    "    return (\n",
    "        str(name).strip().lower()\n",
    "        .replace(\" \", \"\").replace(\"_\", \"\")\n",
    "        .replace(\"-\", \"\").replace(\"/\", \"\")\n",
    "        .replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    )\n",
    "\n",
    "\n",
    "def _pick_first_match(normalized_to_original: Dict[str, str], candidates: List[str]) -> Optional[str]:\n",
    "    \"\"\"Pick the first matching column name from candidates.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in normalized_to_original:\n",
    "            return normalized_to_original[c]\n",
    "    return None\n",
    "\n",
    "\n",
    "def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Standardize column names and clean data.\"\"\"\n",
    "    normalized_to_original = {_normalize_col_name(c): c for c in df.columns}\n",
    "    mapping = {}\n",
    "\n",
    "    # Map common column name variations\n",
    "    location_col = _pick_first_match(\n",
    "        normalized_to_original,\n",
    "        [\"location\", \"locality\", \"area\", \"city\", \"address\", \"region\"]\n",
    "    )\n",
    "    size_col = _pick_first_match(\n",
    "        normalized_to_original,\n",
    "        [\"size\", \"type\", \"propertytype\", \"bhk\", \"bedroom\"]\n",
    "    )\n",
    "    sqft_col = _pick_first_match(\n",
    "        normalized_to_original,\n",
    "        [\"totalsqfeet\", \"totalsqft\", \"squarefeet\", \"sqft\", \"area\"]\n",
    "    )\n",
    "    bathroom_col = _pick_first_match(\n",
    "        normalized_to_original,\n",
    "        [\"bathroom\", \"bathrooms\", \"bath\"]\n",
    "    )\n",
    "    price_col = _pick_first_match(\n",
    "        normalized_to_original,\n",
    "        [\"priceinlakhs\", \"pricelakhs\", \"price\", \"cost\"]\n",
    "    )\n",
    "\n",
    "    # Create mapping\n",
    "    if location_col:\n",
    "        mapping[location_col] = \"location\"\n",
    "    if size_col:\n",
    "        mapping[size_col] = \"size\"\n",
    "    if sqft_col:\n",
    "        mapping[sqft_col] = \"total_sqft\"\n",
    "    if bathroom_col:\n",
    "        mapping[bathroom_col] = \"bath\"\n",
    "    if price_col:\n",
    "        mapping[price_col] = \"price\"\n",
    "\n",
    "    df = df.rename(columns=mapping)\n",
    "    \n",
    "    # Extract BHK number from size column\n",
    "    if \"size\" in df.columns:\n",
    "        df[\"bhk\"] = df[\"size\"].apply(extract_bhk_number)\n",
    "    \n",
    "    # Clean numeric columns\n",
    "    if \"total_sqft\" in df.columns:\n",
    "        df[\"total_sqft\"] = df[\"total_sqft\"].apply(clean_numeric_range)\n",
    "        df[\"total_sqft\"] = pd.to_numeric(df[\"total_sqft\"], errors='coerce')\n",
    "    \n",
    "    if \"bath\" in df.columns:\n",
    "        df[\"bath\"] = pd.to_numeric(df[\"bath\"], errors='coerce')\n",
    "    \n",
    "    if \"price\" in df.columns:\n",
    "        df[\"price\"] = pd.to_numeric(df[\"price\"], errors='coerce')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def build_preprocessor(categorical_features: List[str], numeric_features: List[str]) -> ColumnTransformer:\n",
    "    \"\"\"Build preprocessing pipeline.\"\"\"\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    return ColumnTransformer(transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "\n",
    "def evaluate_model(y_true: pd.Series, y_pred: np.ndarray) -> dict:\n",
    "    \"\"\"Calculate evaluation metrics.\"\"\"\n",
    "    return {\n",
    "        \"R2\": float(r2_score(y_true, y_pred)),\n",
    "        \"MAE\": float(mean_absolute_error(y_true, y_pred)),\n",
    "        \"RMSE\": float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ 3. Load Dataset\n",
    "\n",
    "**Note:** Update the `DATA_PATH` variable to point to your dataset file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = \"data/house_prices.xlsx\"  # Update this path\n",
    "\n",
    "# Load dataset\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(f\"‚ùå ERROR: Dataset not found at: {DATA_PATH}\")\n",
    "    print(\"\\nPlease update the DATA_PATH variable to point to your dataset.\")\n",
    "else:\n",
    "    # Load based on file extension\n",
    "    _, ext = os.path.splitext(DATA_PATH.lower())\n",
    "    if ext in {\".xlsx\", \".xls\"}:\n",
    "        df_raw = pd.read_excel(DATA_PATH)\n",
    "    elif ext == \".csv\":\n",
    "        df_raw = pd.read_csv(DATA_PATH)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use .csv or .xlsx\")\n",
    "    \n",
    "    # Strip whitespace from column names\n",
    "    df_raw.columns = df_raw.columns.str.strip()\n",
    "    \n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"   Rows: {df_raw.shape[0]:,}\")\n",
    "    print(f\"   Columns: {df_raw.shape[1]}\")\n",
    "    print(f\"\\nüìã Column Names: {list(df_raw.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Display First Few Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIRST 5 ROWS OF DATASET\")\n",
    "print(\"=\"*80)\n",
    "display(df_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*80)\n",
    "print(df_raw.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA TYPES\")\n",
    "print(\"=\"*80)\n",
    "print(df_raw.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ 4. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA CLEANING AND PREPROCESSING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Standardize column names\n",
    "print(\"\\n[1/4] Standardizing column names...\")\n",
    "df = standardize_columns(df_raw.copy())\n",
    "print(f\"‚úÖ Columns standardized: {list(df.columns)}\")\n",
    "\n",
    "# Remove duplicates\n",
    "print(\"\\n[2/4] Removing duplicate rows...\")\n",
    "initial_rows = len(df)\n",
    "df = df.drop_duplicates()\n",
    "duplicates_removed = initial_rows - len(df)\n",
    "print(f\"‚úÖ Removed {duplicates_removed} duplicate rows\")\n",
    "\n",
    "# Drop rows with missing target\n",
    "print(\"\\n[3/4] Removing rows with missing target (price)...\")\n",
    "initial_rows = len(df)\n",
    "df = df.dropna(subset=['price'])\n",
    "missing_price_removed = initial_rows - len(df)\n",
    "print(f\"‚úÖ Removed {missing_price_removed} rows with missing price\")\n",
    "\n",
    "# Feature engineering\n",
    "print(\"\\n[4/4] Feature engineering...\")\n",
    "if 'total_sqft' in df.columns and 'bhk' in df.columns:\n",
    "    df['price_per_sqft'] = df['price'] / df['total_sqft']\n",
    "    print(\"‚úÖ Created feature: price_per_sqft\")\n",
    "\n",
    "print(f\"\\n‚úÖ Data cleaning complete! Final dataset: {len(df)} rows, {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Display Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLEANED DATASET - FIRST 10 ROWS\")\n",
    "print(\"=\"*80)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 5. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing Count': missing_values.values,\n",
    "    'Percentage': missing_percent.values\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    display(missing_df)\n",
    "    \n",
    "    # Visualize missing values\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    missing_df.plot(x='Column', y='Percentage', kind='bar', ax=ax, color='coral', legend=False)\n",
    "    plt.title('Missing Values by Column', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Column Name', fontsize=12)\n",
    "    plt.ylabel('Percentage Missing (%)', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"‚úÖ No missing values found in any column!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Price Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PRICE DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['price'].dropna(), bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Price Distribution (Histogram)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Price (Lakhs)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# KDE Plot\n",
    "df['price'].dropna().plot(kind='density', ax=axes[1], color='darkblue', linewidth=2)\n",
    "axes[1].set_title('Price Distribution (Density)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Price (Lakhs)', fontsize=12)\n",
    "axes[1].set_ylabel('Density', fontsize=12)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Price statistics\n",
    "print(f\"\\nPrice Statistics:\")\n",
    "print(f\"  Mean: ‚Çπ{df['price'].mean():.2f} Lakhs\")\n",
    "print(f\"  Median: ‚Çπ{df['price'].median():.2f} Lakhs\")\n",
    "print(f\"  Std Dev: ‚Çπ{df['price'].std():.2f} Lakhs\")\n",
    "print(f\"  Min: ‚Çπ{df['price'].min():.2f} Lakhs\")\n",
    "print(f\"  Max: ‚Çπ{df['price'].max():.2f} Lakhs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "if len(numeric_cols) > 1:\n",
    "    correlation_matrix = df[numeric_cols].corr()\n",
    "    \n",
    "    # Display correlation with price\n",
    "    if 'price' in correlation_matrix.columns:\n",
    "        price_corr = correlation_matrix['price'].sort_values(ascending=False)\n",
    "        print(\"\\nCorrelation with Price:\")\n",
    "        print(price_corr)\n",
    "    \n",
    "    # Heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                fmt='.2f', square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"‚ö†Ô∏è Not enough numeric columns for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 BHK vs Price Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BHK vs PRICE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'bhk' in df.columns and 'price' in df.columns:\n",
    "    df_bhk = df.dropna(subset=['bhk', 'price'])\n",
    "    \n",
    "    # Statistics by BHK\n",
    "    bhk_stats = df_bhk.groupby('bhk')['price'].agg(['count', 'mean', 'median', 'std'])\n",
    "    bhk_stats.columns = ['Count', 'Mean Price', 'Median Price', 'Std Dev']\n",
    "    print(\"\\nPrice Statistics by BHK:\")\n",
    "    display(bhk_stats)\n",
    "    \n",
    "    # Visualizations\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Box plot\n",
    "    sns.boxplot(x='bhk', y='price', data=df_bhk, ax=axes[0], palette='Set2')\n",
    "    axes[0].set_title('Price Distribution by BHK (Box Plot)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('BHK', fontsize=12)\n",
    "    axes[0].set_ylabel('Price (Lakhs)', fontsize=12)\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Violin plot\n",
    "    sns.violinplot(x='bhk', y='price', data=df_bhk, ax=axes[1], palette='Set3')\n",
    "    axes[1].set_title('Price Distribution by BHK (Violin Plot)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('BHK', fontsize=12)\n",
    "    axes[1].set_ylabel('Price (Lakhs)', fontsize=12)\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"‚ö†Ô∏è BHK or Price column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Area (Square Feet) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AREA (SQUARE FEET) ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'total_sqft' in df.columns and 'price' in df.columns:\n",
    "    df_sqft = df.dropna(subset=['total_sqft', 'price'])\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[0].scatter(df_sqft['total_sqft'], df_sqft['price'], alpha=0.5, color='navy')\n",
    "    axes[0].set_title('Price vs Total Square Feet', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Total Square Feet', fontsize=12)\n",
    "    axes[0].set_ylabel('Price (Lakhs)', fontsize=12)\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Hexbin plot for density\n",
    "    axes[1].hexbin(df_sqft['total_sqft'], df_sqft['price'], gridsize=30, cmap='YlOrRd')\n",
    "    axes[1].set_title('Price vs Total Square Feet (Density)', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Total Square Feet', fontsize=12)\n",
    "    axes[1].set_ylabel('Price (Lakhs)', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation\n",
    "    corr = df_sqft['total_sqft'].corr(df_sqft['price'])\n",
    "    print(f\"\\nüìä Correlation between Total Sqft and Price: {corr:.4f}\")\nelse:\n",
    "    print(\"‚ö†Ô∏è total_sqft or price column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Top Locations by Average Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP LOCATIONS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'location' in df.columns and 'price' in df.columns:\n",
    "    location_stats = df.groupby('location')['price'].agg(['count', 'mean', 'median']).reset_index()\n",
    "    location_stats.columns = ['Location', 'Count', 'Mean Price', 'Median Price']\n",
    "    location_stats = location_stats.sort_values('Mean Price', ascending=False)\n",
    "    \n",
    "    # Top 15 locations by average price\n",
    "    top_locations = location_stats.head(15)\n",
    "    \n",
    "    print(\"\\nTop 15 Locations by Average Price:\")\n",
    "    display(top_locations)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(range(len(top_locations)), top_locations['Mean Price'], color='teal')\n",
    "    plt.yticks(range(len(top_locations)), top_locations['Location'])\n",
    "    plt.xlabel('Average Price (Lakhs)', fontsize=12)\n",
    "    plt.ylabel('Location', fontsize=12)\n",
    "    plt.title('Top 15 Locations by Average Price', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"‚ö†Ô∏è location or price column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ 6. Model Training and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREPARING FEATURES AND TARGET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check required columns\n",
    "required_cols = ['location', 'total_sqft', 'bath', 'bhk', 'price']\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "\n",
    "if missing:\n",
    "    raise ValueError(f\"‚ùå Missing required columns: {missing}\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df[['location', 'total_sqft', 'bath', 'bhk']].copy()\n",
    "y = df['price'].copy()\n",
    "\n",
    "print(f\"‚úÖ Features selected: {list(X.columns)}\")\n",
    "print(f\"‚úÖ Target variable: price\")\n",
    "print(f\"‚úÖ Total samples: {len(X):,}\")\n",
    "print(f\"\\nFeature data types:\")\n",
    "print(X.dtypes)\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SPLITTING DATA INTO TRAIN AND TEST SETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training set: {len(X_train):,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"‚úÖ Test set: {len(X_test):,} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nTrain set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Build Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUILDING PREPROCESSING PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "categorical_features = ['location']\n",
    "numeric_features = ['total_sqft', 'bath', 'bhk']\n",
    "\n",
    "preprocessor = build_preprocessor(categorical_features, numeric_features)\n",
    "\n",
    "print(f\"‚úÖ Categorical features: {categorical_features}\")\n",
    "print(f\"‚úÖ Numeric features: {numeric_features}\")\n",
    "print(f\"\\nPreprocessing steps:\")\n",
    "print(\"  - Categorical: Imputation (most frequent) ‚Üí One-Hot Encoding\")\n",
    "print(\"  - Numeric: Imputation (median) ‚Üí Standard Scaling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING AND COMPARING 8 MACHINE LEARNING MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0, random_state=42),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.1, random_state=42),\n",
    "    \"ElasticNet Regression\": ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=42, max_depth=15),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42, max_depth=15),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=5),\n",
    "    \"Support Vector Regressor (SVR)\": SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_score = -np.inf\n",
    "best_model_name = None\n",
    "best_pipeline = None\n",
    "trained_pipelines = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training: {name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Train\n",
    "    print(\"  ‚è≥ Training model...\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print(\"  ‚úÖ Training complete\")\n",
    "    \n",
    "    # Predict\n",
    "    print(\"  ‚è≥ Making predictions...\")\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(\"  ‚úÖ Predictions complete\")\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"  ‚è≥ Evaluating model...\")\n",
    "    metrics = evaluate_model(y_test, y_pred)\n",
    "    \n",
    "    # Cross-validation\n",
    "    print(\"  ‚è≥ Performing 5-fold cross-validation...\")\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='r2')\n",
    "    metrics['CV_R2_Mean'] = float(cv_scores.mean())\n",
    "    metrics['CV_R2_Std'] = float(cv_scores.std())\n",
    "    print(\"  ‚úÖ Cross-validation complete\")\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\"Model\": name, **metrics})\n",
    "    trained_pipelines[name] = pipeline\n",
    "    \n",
    "    # Display metrics\n",
    "    print(f\"\\n  üìä Performance Metrics:\")\n",
    "    print(f\"     R¬≤ Score (Test): {metrics['R2']:.4f}\")\n",
    "    print(f\"     MAE: ‚Çπ{metrics['MAE']:.2f} Lakhs\")\n",
    "    print(f\"     RMSE: ‚Çπ{metrics['RMSE']:.2f} Lakhs\")\n",
    "    print(f\"     CV R¬≤ (mean¬±std): {metrics['CV_R2_Mean']:.4f} ¬± {metrics['CV_R2_Std']:.4f}\")\n",
    "    \n",
    "    # Track best model\n",
    "    if metrics['R2'] > best_score:\n",
    "        best_score = metrics['R2']\n",
    "        best_model_name = name\n",
    "        best_pipeline = pipeline\n",
    "        print(f\"\\n  üèÜ NEW BEST MODEL!\")\n",
    "\n",
    "print(f\"\\n\\n\" + \"=\"*80)\n",
    "print(\"MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Model Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results).sort_values(by='R2', ascending=False)\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "print(f\"   R¬≤ Score: {best_score:.4f}\\n\")\n",
    "\n",
    "print(\"\\nAll Models Comparison (sorted by R¬≤ Score):\")\n",
    "display(results_df.style.highlight_max(subset=['R2', 'CV_R2_Mean'], color='lightgreen')\n",
    "                         .highlight_min(subset=['MAE', 'RMSE'], color='lightcoral')\n",
    "                         .format({\n",
    "                             'R2': '{:.4f}',\n",
    "                             'MAE': '{:.2f}',\n",
    "                             'RMSE': '{:.2f}',\n",
    "                             'CV_R2_Mean': '{:.4f}',\n",
    "                             'CV_R2_Std': '{:.4f}'\n",
    "                         }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Visualize Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL PERFORMANCE VISUALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. R¬≤ Score Comparison\n",
    "ax1 = axes[0, 0]\n",
    "colors = ['gold' if model == best_model_name else 'skyblue' for model in results_df['Model']]\n",
    "ax1.barh(results_df['Model'], results_df['R2'], color=colors, edgecolor='black')\n",
    "ax1.set_xlabel('R¬≤ Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Model Comparison - R¬≤ Score', fontsize=14, fontweight='bold')\n",
    "ax1.grid(alpha=0.3, axis='x')\n",
    "ax1.invert_yaxis()\n",
    "for i, v in enumerate(results_df['R2']):\n",
    "    ax1.text(v + 0.01, i, f'{v:.4f}', va='center', fontweight='bold')\n",
    "\n",
    "# 2. MAE Comparison\n",
    "ax2 = axes[0, 1]\n",
    "ax2.barh(results_df['Model'], results_df['MAE'], color='coral', edgecolor='black')\n",
    "ax2.set_xlabel('Mean Absolute Error (Lakhs)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Model Comparison - MAE (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "ax2.grid(alpha=0.3, axis='x')\n",
    "ax2.invert_yaxis()\n",
    "for i, v in enumerate(results_df['MAE']):\n",
    "    ax2.text(v + 0.5, i, f'‚Çπ{v:.2f}', va='center', fontweight='bold')\n",
    "\n",
    "# 3. RMSE Comparison\n",
    "ax3 = axes[1, 0]\n",
    "ax3.barh(results_df['Model'], results_df['RMSE'], color='lightgreen', edgecolor='black')\n",
    "ax3.set_xlabel('Root Mean Square Error (Lakhs)', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Model Comparison - RMSE (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "ax3.grid(alpha=0.3, axis='x')\n",
    "ax3.invert_yaxis()\n",
    "for i, v in enumerate(results_df['RMSE']):\n",
    "    ax3.text(v + 0.5, i, f'‚Çπ{v:.2f}', va='center', fontweight='bold')\n",
    "\n",
    "# 4. Cross-Validation R¬≤ Score\n",
    "ax4 = axes[1, 1]\n",
    "colors = ['gold' if model == best_model_name else 'plum' for model in results_df['Model']]\n",
    "ax4.barh(results_df['Model'], results_df['CV_R2_Mean'], \n",
    "         xerr=results_df['CV_R2_Std'], color=colors, edgecolor='black', capsize=5)\n",
    "ax4.set_xlabel('Cross-Validation R¬≤ Score', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Model Comparison - CV R¬≤ Score (with std)', fontsize=14, fontweight='bold')\n",
    "ax4.grid(alpha=0.3, axis='x')\n",
    "ax4.invert_yaxis()\n",
    "for i, (mean, std) in enumerate(zip(results_df['CV_R2_Mean'], results_df['CV_R2_Std'])):\n",
    "    ax4.text(mean + 0.01, i, f'{mean:.4f}¬±{std:.4f}', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Actual vs Predicted (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"ACTUAL vs PREDICTED - {best_model_name}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get predictions from best model\n",
    "y_pred_best = best_pipeline.predict(X_test)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_test, y_pred_best, alpha=0.6, color='navy', edgecolors='black')\n",
    "ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', lw=3, label='Perfect Prediction')\n",
    "ax1.set_xlabel('Actual Price (Lakhs)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Predicted Price (Lakhs)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title(f'Actual vs Predicted - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "ax2 = axes[1]\n",
    "residuals = y_test - y_pred_best\n",
    "ax2.scatter(y_pred_best, residuals, alpha=0.6, color='darkgreen', edgecolors='black')\n",
    "ax2.axhline(y=0, color='r', linestyle='--', lw=3)\n",
    "ax2.set_xlabel('Predicted Price (Lakhs)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Residuals (Lakhs)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title(f'Residual Plot - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residual statistics\n",
    "print(f\"\\nResidual Statistics:\")\n",
    "print(f\"  Mean Residual: ‚Çπ{residuals.mean():.2f} Lakhs\")\n",
    "print(f\"  Std Residual: ‚Çπ{residuals.std():.2f} Lakhs\")\n",
    "print(f\"  Min Residual: ‚Çπ{residuals.min():.2f} Lakhs\")\n",
    "print(f\"  Max Residual: ‚Çπ{residuals.max():.2f} Lakhs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÆ 7. Interactive Prediction System\n",
    "\n",
    "Use the best trained model to make predictions for custom inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Get Available Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique locations from dataset\n",
    "available_locations = sorted(df['location'].dropna().unique().tolist())\n",
    "\n",
    "print(f\"\\nüìç Available Locations ({len(available_locations)} total):\")\n",
    "print(\"\\nShowing first 30 locations:\")\n",
    "for i, loc in enumerate(available_locations[:30], 1):\n",
    "    print(f\"  {i}. {loc}\")\n",
    "\n",
    "if len(available_locations) > 30:\n",
    "    print(f\"\\n... and {len(available_locations) - 30} more locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Make Predictions - Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREDICTION EXAMPLE 1\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Example input - Modify these values\n",
    "example_1 = {\n",
    "    'location': available_locations[0] if available_locations else 'Rajaji Nagar',\n",
    "    'total_sqft': 1500.0,\n",
    "    'bath': 2.0,\n",
    "    'bhk': 3.0\n",
    "}\n",
    "\n",
    "# Create input dataframe\n",
    "input_df_1 = pd.DataFrame([example_1])\n",
    "\n",
    "print(\"\\nüìã Input Details:\")\n",
    "display(input_df_1)\n",
    "\n",
    "# Make prediction\n",
    "prediction_1 = best_pipeline.predict(input_df_1)[0]\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"üí∞ PREDICTED PRICE\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"\\n  ‚Çπ{prediction_1:.2f} Lakhs\")\n",
    "print(f\"  (‚Çπ{prediction_1*100000:,.0f} Rupees)\")\n",
    "\n",
    "# Calculate price per sqft\n",
    "price_per_sqft = (prediction_1 * 100000) / example_1['total_sqft']\n",
    "print(f\"\\nüìä Price Analysis:\")\n",
    "print(f\"  Price per sqft: ‚Çπ{price_per_sqft:,.0f}\")\n",
    "print(f\"  Total Price: ‚Çπ{prediction_1:.2f} Lakhs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Make Predictions - Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREDICTION EXAMPLE 2\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Example input - Modify these values\n",
    "example_2 = {\n",
    "    'location': available_locations[5] if len(available_locations) > 5 else available_locations[0],\n",
    "    'total_sqft': 2000.0,\n",
    "    'bath': 3.0,\n",
    "    'bhk': 4.0\n",
    "}\n",
    "\n",
    "# Create input dataframe\n",
    "input_df_2 = pd.DataFrame([example_2])\n",
    "\n",
    "print(\"\\nüìã Input Details:\")\n",
    "display(input_df_2)\n",
    "\n",
    "# Make prediction\n",
    "prediction_2 = best_pipeline.predict(input_df_2)[0]\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"üí∞ PREDICTED PRICE\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"\\n  ‚Çπ{prediction_2:.2f} Lakhs\")\n",
    "print(f\"  (‚Çπ{prediction_2*100000:,.0f} Rupees)\")\n",
    "\n",
    "# Calculate price per sqft\n",
    "price_per_sqft = (prediction_2 * 100000) / example_2['total_sqft']\n",
    "print(f\"\\nüìä Price Analysis:\")\n",
    "print(f\"  Price per sqft: ‚Çπ{price_per_sqft:,.0f}\")\n",
    "print(f\"  Total Price: ‚Çπ{prediction_2:.2f} Lakhs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Batch Predictions - Compare Multiple Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH PREDICTIONS - COMPARE MULTIPLE PROPERTIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create multiple property scenarios\n",
    "batch_properties = pd.DataFrame([\n",
    "    {'location': available_locations[0] if available_locations else 'Rajaji Nagar', \n",
    "     'total_sqft': 1000, 'bath': 2, 'bhk': 2, 'property': '2 BHK Apartment'},\n",
    "    {'location': available_locations[0] if available_locations else 'Rajaji Nagar', \n",
    "     'total_sqft': 1500, 'bath': 2, 'bhk': 3, 'property': '3 BHK Apartment'},\n",
    "    {'location': available_locations[0] if available_locations else 'Rajaji Nagar', \n",
    "     'total_sqft': 2000, 'bath': 3, 'bhk': 4, 'property': '4 BHK Villa'},\n",
    "    {'location': available_locations[0] if available_locations else 'Rajaji Nagar', \n",
    "     'total_sqft': 2500, 'bath': 4, 'bhk': 5, 'property': '5 BHK Luxury Villa'},\n",
    "])\n",
    "\n",
    "# Make predictions\n",
    "prediction_features = batch_properties[['location', 'total_sqft', 'bath', 'bhk']]\n",
    "batch_predictions = best_pipeline.predict(prediction_features)\n",
    "batch_properties['predicted_price_lakhs'] = batch_predictions\n",
    "batch_properties['predicted_price_rupees'] = batch_predictions * 100000\n",
    "batch_properties['price_per_sqft'] = batch_properties['predicted_price_rupees'] / batch_properties['total_sqft']\n",
    "\n",
    "print(\"\\nComparison of Different Property Types:\")\n",
    "display(batch_properties[['property', 'bhk', 'total_sqft', 'bath', \n",
    "                          'predicted_price_lakhs', 'price_per_sqft']].style.format({\n",
    "    'predicted_price_lakhs': '‚Çπ{:.2f} L',\n",
    "    'price_per_sqft': '‚Çπ{:.0f}',\n",
    "    'total_sqft': '{:.0f}'\n",
    "}))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Price comparison\n",
    "ax1 = axes[0]\n",
    "ax1.bar(range(len(batch_properties)), batch_properties['predicted_price_lakhs'], \n",
    "        color=['skyblue', 'lightgreen', 'coral', 'gold'], edgecolor='black', linewidth=2)\n",
    "ax1.set_xticks(range(len(batch_properties)))\n",
    "ax1.set_xticklabels(batch_properties['property'], rotation=15, ha='right')\n",
    "ax1.set_ylabel('Predicted Price (Lakhs)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Price Comparison Across Property Types', fontsize=14, fontweight='bold')\n",
    "ax1.grid(alpha=0.3, axis='y')\n",
    "for i, v in enumerate(batch_properties['predicted_price_lakhs']):\n",
    "    ax1.text(i, v + 5, f'‚Çπ{v:.1f}L', ha='center', fontweight='bold')\n",
    "\n",
    "# Price per sqft comparison\n",
    "ax2 = axes[1]\n",
    "ax2.bar(range(len(batch_properties)), batch_properties['price_per_sqft'], \n",
    "        color=['skyblue', 'lightgreen', 'coral', 'gold'], edgecolor='black', linewidth=2)\n",
    "ax2.set_xticks(range(len(batch_properties)))\n",
    "ax2.set_xticklabels(batch_properties['property'], rotation=15, ha='right')\n",
    "ax2.set_ylabel('Price per Sqft (‚Çπ)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Price per Sqft Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.grid(alpha=0.3, axis='y')\n",
    "for i, v in enumerate(batch_properties['price_per_sqft']):\n",
    "    ax2.text(i, v + 100, f'‚Çπ{v:.0f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Custom Prediction Function\n",
    "\n",
    "Create your own predictions by modifying the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_house_price(location, sqft, bathrooms, bedrooms):\n",
    "    \"\"\"\n",
    "    Predict house price based on input parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    location : str\n",
    "        Location of the property\n",
    "    sqft : float\n",
    "        Total area in square feet\n",
    "    bathrooms : int\n",
    "        Number of bathrooms\n",
    "    bedrooms : int\n",
    "        Number of bedrooms (BHK)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing prediction results\n",
    "    \"\"\"\n",
    "    # Create input dataframe\n",
    "    input_data = pd.DataFrame([{\n",
    "        'location': location,\n",
    "        'total_sqft': float(sqft),\n",
    "        'bath': float(bathrooms),\n",
    "        'bhk': float(bedrooms)\n",
    "    }])\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction_lakhs = best_pipeline.predict(input_data)[0]\n",
    "    prediction_rupees = prediction_lakhs * 100000\n",
    "    price_per_sqft = prediction_rupees / sqft\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üè† HOUSE PRICE PREDICTION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nüìç Location: {location}\")\n",
    "    print(f\"üõèÔ∏è  BHK: {bedrooms}\")\n",
    "    print(f\"üöø Bathrooms: {bathrooms}\")\n",
    "    print(f\"üìè Total Area: {sqft:,.0f} sq ft\")\n",
    "    print(f\"\\n\" + \"-\"*80)\n",
    "    print(f\"üí∞ Predicted Price: ‚Çπ{prediction_lakhs:.2f} Lakhs\")\n",
    "    print(f\"üíµ In Rupees: ‚Çπ{prediction_rupees:,.0f}\")\n",
    "    print(f\"üìä Price per sq ft: ‚Çπ{price_per_sqft:,.0f}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return {\n",
    "        'price_lakhs': prediction_lakhs,\n",
    "        'price_rupees': prediction_rupees,\n",
    "        'price_per_sqft': price_per_sqft\n",
    "    }\n",
    "\n",
    "# Example usage - Modify these values to make your own predictions\n",
    "result = predict_house_price(\n",
    "    location=available_locations[0] if available_locations else 'Rajaji Nagar',\n",
    "    sqft=1800,\n",
    "    bathrooms=3,\n",
    "    bedrooms=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 8. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING MODEL AND RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"models\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save best model\n",
    "model_path = os.path.join(output_dir, \"house_price_model.pkl\")\n",
    "joblib.dump(best_pipeline, model_path)\n",
    "print(f\"\\n‚úÖ Best model saved: {model_path}\")\n",
    "print(f\"   Model: {best_model_name}\")\n",
    "\n",
    "# Save model comparison\n",
    "comparison_path = os.path.join(output_dir, \"model_comparison.csv\")\n",
    "results_df.to_csv(comparison_path, index=False)\n",
    "print(f\"\\n‚úÖ Model comparison saved: {comparison_path}\")\n",
    "\n",
    "# Save metrics JSON\n",
    "metrics_data = {\n",
    "    \"best_model\": best_model_name,\n",
    "    \"best_metrics\": results_df.iloc[0].to_dict(),\n",
    "    \"all_models\": results,\n",
    "    \"training_info\": {\n",
    "        \"total_samples\": len(df),\n",
    "        \"train_samples\": len(X_train),\n",
    "        \"test_samples\": len(X_test),\n",
    "        \"features\": list(X.columns),\n",
    "        \"test_size\": 0.2,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "}\n",
    "\n",
    "metrics_path = os.path.join(output_dir, \"metrics.json\")\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics_data, f, indent=2)\n",
    "print(f\"\\n‚úÖ Metrics saved: {metrics_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL FILES SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã 9. Project Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = f\"\"\"\n",
    "üè† HOUSE PRICE PREDICTION PROJECT\n",
    "{'='*80}\n",
    "\n",
    "üìä DATASET INFORMATION:\n",
    "  ‚Ä¢ Total Records: {len(df):,}\n",
    "  ‚Ä¢ Features: {list(X.columns)}\n",
    "  ‚Ä¢ Target: price (in Lakhs)\n",
    "  ‚Ä¢ Locations: {len(available_locations)}\n",
    "\n",
    "üî¨ MODELS TRAINED:\n",
    "  ‚Ä¢ Total Models: 8\n",
    "  ‚Ä¢ Linear Models: 4 (Linear, Ridge, Lasso, ElasticNet)\n",
    "  ‚Ä¢ Non-Linear Models: 4 (Decision Tree, Random Forest, Gradient Boosting, SVR)\n",
    "\n",
    "üèÜ BEST MODEL:\n",
    "  ‚Ä¢ Model: {best_model_name}\n",
    "  ‚Ä¢ R¬≤ Score: {best_score:.4f}\n",
    "  ‚Ä¢ MAE: ‚Çπ{results_df.iloc[0]['MAE']:.2f} Lakhs\n",
    "  ‚Ä¢ RMSE: ‚Çπ{results_df.iloc[0]['RMSE']:.2f} Lakhs\n",
    "  ‚Ä¢ CV R¬≤ Score: {results_df.iloc[0]['CV_R2_Mean']:.4f} ¬± {results_df.iloc[0]['CV_R2_Std']:.4f}\n",
    "\n",
    "üìÅ OUTPUT FILES:\n",
    "  ‚Ä¢ Model: {model_path}\n",
    "  ‚Ä¢ Comparison: {comparison_path}\n",
    "  ‚Ä¢ Metrics: {metrics_path}\n",
    "\n",
    "‚ú® PROJECT COMPLETED SUCCESSFULLY!\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Conclusion\n",
    "\n",
    "This notebook demonstrates a complete end-to-end machine learning pipeline for house price prediction:\n",
    "\n",
    "1. ‚úÖ **Data Loading & Preprocessing**: Handled various data formats and cleaned data\n",
    "2. ‚úÖ **Exploratory Data Analysis**: Comprehensive analysis with visualizations\n",
    "3. ‚úÖ **Feature Engineering**: Created meaningful features like price_per_sqft\n",
    "4. ‚úÖ **Model Training**: Trained and compared 8 different ML models\n",
    "5. ‚úÖ **Model Evaluation**: Used multiple metrics (R¬≤, MAE, RMSE) and cross-validation\n",
    "6. ‚úÖ **Model Selection**: Automatically selected the best performing model\n",
    "7. ‚úÖ **Prediction System**: Interactive system for making predictions\n",
    "8. ‚úÖ **Results Export**: Saved model and metrics for future use\n",
    "\n",
    "### üìù Key Takeaways:\n",
    "\n",
    "- The best model achieved an R¬≤ score of **{:.4f}**, indicating good predictive performance\n",
    "- Location, square footage, and number of bedrooms are key factors in house pricing\n",
    "- The model can be used to estimate house prices for new properties\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "- Try hyperparameter tuning to improve model performance\n",
    "- Add more features (age of property, amenities, etc.)\n",
    "- Experiment with ensemble methods\n",
    "- Deploy the model as a web application\n",
    "\n",
    "---\n",
    "\n",
    "**Created by:** House Price Prediction ML Pipeline  \n",
    "**Date:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}  \n",
    "**Best Model:** {best_model_name}  \n",
    "**R¬≤ Score:** {best_score:.4f}\n",
    "\"\"\".format(best_score, best_model_name, best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
